---
title: Roadmap
description: Future plans
---

## Milestone 0 (Completed)

-   [X] OpenAI compatible API
-   [X] Models: `google-gemma-2b-it`

## Milestone 1 (Completed)

-   [X] API authorization with Dex
-   [X] API key management
-   [X] Quota management for fine-tuning jobs
-   [X] Inference autoscaling with GPU utilization
-   [X] Models: `Mistral-7B-Instruct`, `Meta-Llama-3-8B-Instruct`, and `google-gemma-7b-it`

## Milestone 2 (Completed)

-   [X] Jupyter Notebook workspace creation
-   [X] Dynamic model loading & offloading in inference (initial version)
-   [X] Organization & project management
-   [X] MLflow integration
-   [X] Weights & Biases integration for fine-tuning jobs
-   [X] VectorDB installation and RAG
-   [X] Multi k8s cluster deployment (initial version)

## Milestone 3 (Completed)

-   [X] Object store other than MinIO
-   [X] Multi-GPU general-purpose training jobs
-   [X] Inference optimization (e.g., vLLM)
-   [X] Models: `Meta-Llama-3-8B-Instruct`, `Meta-Llama-3-70B-Instruct`, `deepseek-coder-6.7b-base`

## Milestone 4 (In-progress)

-   [X] Embedding API
-   [ ] API usage visibility
-   [ ] Fine-tuning support with vLLM
-   [ ] High availability
-   [ ] Frontend
-   [ ] GPU showback
-   [ ] Non-Nvidia GPU support
-   [ ] Multi k8s cluster deployment (file and vector store management)
-   [ ] Monitoring & alerting
-   [ ] More models

## Milestone 5

-   [ ] Multi-GPU LLM fine-tuning jobs
-   [ ] Events and metrics for fine-tuning jobs
